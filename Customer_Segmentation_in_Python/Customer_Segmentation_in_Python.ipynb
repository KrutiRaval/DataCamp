{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation in Python\n",
    "\n",
    "### Assign daily acquisition cohort\n",
    "As you have seen in the video, defining a cohort is the first step to cohort analysis. You will now create daily cohorts based on the day each customer has made their first transaction.\n",
    "\n",
    "The data has been loaded as online DataFrame, you can now print its header with online.head() in the console.\n",
    "```python\n",
    "# Define a function that will parse the date\n",
    "def get_day(x): return dt.datetime(x.year, x.month, x.day) \n",
    "\n",
    "# Create InvoiceDay column\n",
    "online['InvoiceDay'] = online['InvoiceDate'].apply(get_day) \n",
    "\n",
    "# Group by CustomerID and select the InvoiceDay value\n",
    "grouping = online.groupby('CustomerID')['InvoiceDate'] \n",
    "\n",
    "# Assign a minimum InvoiceDay value to the dataset\n",
    "online['CohortDay'] = grouping.transform('min')\n",
    "\n",
    "# View the top 5 rows\n",
    "print(online.head())\n",
    "\n",
    "```\n",
    "Calculate time offset in days - part 1\n",
    "Calculating time offset for each transaction allows you to report the metrics for each cohort in a comparable fashion.\n",
    "\n",
    "First, we will create 6 variables that capture the integer value of years, months and days for Invoice and Cohort Date using the get_date_int() function that's been already defined for you:\n",
    "```python\n",
    "def get_date_int(df, column):\n",
    "    year = df[column].dt.year\n",
    "    month = df[column].dt.month\n",
    "    day = df[column].dt.day\n",
    "    return year, month, day\n",
    "```\n",
    "The online data has been loaded, you can print its header to the console by calling online.head().\n",
    "\n",
    "```python\n",
    "# Get the integers for date parts from the `InvoiceDay` column\n",
    "invoice_year, invoice_month, invoice_day = get_date_int(online, 'InvoiceDay')\n",
    "\n",
    "# Get the integers for date parts from the `CohortDay` column\n",
    "cohort_year, cohort_month, cohort_day = get_date_int(online, 'CohortDay')\n",
    "\n",
    "```\n",
    "### Calculate time offset in days - part 2\n",
    "Great work! Now, we have six different data sets with year, month and day values for Invoice and Cohort dates - invoice_year, cohort_year, invoice_month, cohort_month, invoice_day, and cohort_day.\n",
    "\n",
    "In this exercise you will calculate the difference between the Invoice and Cohort dates in years, months and days separately and then calculate the total days difference between the two. This will be your days offset which we will use in the next exercise to visualize the customer count. The online data has been loaded, you can print its header to the console by calling online.head().\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# Calculate difference in years\n",
    "years_diff = invoice_year - cohort_year\n",
    "\n",
    "# Calculate difference in months\n",
    "months_diff = invoice_month - cohort_month\n",
    "\n",
    "# Calculate difference in days\n",
    "days_diff = invoice_day - cohort_day\n",
    "\n",
    "# Extract the difference in days from all previous values\n",
    "online['CohortIndex'] = years_diff * 365 + months_diff * 30 + days_diff + 1\n",
    "print(online.head())\n",
    "\n",
    "```\n",
    "### Calculate retention rate from scratch\n",
    "You have seen how to create retention and average quantity metrics table for the monthly acquisition cohorts. Now it's you time to build the retention metrics by yourself.\n",
    "\n",
    "The online dataset has been loaded to you with monthly cohorts and cohort index assigned from this lesson. Feel free to print it in the Console.\n",
    "\n",
    "Also, we have created a loaded a groupby object as grouping DataFrame with this command: grouping = online.groupby(['CohortMonth', 'CohortIndex'])\n",
    "\n",
    "```python\n",
    "# Count the number of unique values per customer ID\n",
    "cohort_data = grouping['CustomerID'].apply(pd.Series.nunique).reset_index()\n",
    "\n",
    "# Create a pivot \n",
    "cohort_counts = cohort_data.pivot(index='CohortMonth', columns='CohortIndex', values='CustomerID')\n",
    "\n",
    "# Select the first column and store it to cohort_sizes\n",
    "cohort_sizes = cohort_counts.iloc[:,0]\n",
    "\n",
    "# Divide the cohort count by cohort sizes along the rows\n",
    "retention = cohort_counts.divide(cohort_sizes, axis=0)\n",
    "\n",
    "```\n",
    "### Calculate average price\n",
    "You will now calculate the average price metric and analyze if there are any differences in shopping patterns across time and across cohorts.\n",
    "\n",
    "The online dataset has been loaded to you with monthly cohorts and cohort index assigned from this lesson. Feel free to print it to the Console\n",
    "\n",
    "```python\n",
    "# Create a groupby object and pass the monthly cohort and cohort index as a list\n",
    "grouping = online.groupby(['CohortMonth', 'CohortIndex'])\n",
    "\n",
    "# Calculate the average of the unit price column\n",
    "cohort_data = grouping['UnitPrice'].mean()\n",
    "\n",
    "# Reset the index of cohort_data\n",
    "cohort_data = cohort_data.reset_index()\n",
    "\n",
    "# Create a pivot \n",
    "average_price = cohort_data.pivot(index='CohortMonth', columns='CohortIndex', values='UnitPrice')\n",
    "print(average_price.round(1))\n",
    "\n",
    "```\n",
    "### Visualize average quantity metric\n",
    "You are now going to visualize average quantity values in a heatmap.\n",
    "\n",
    "We have loaded pandas package as pd, and the average quantity values DataFrame as average_quantity.\n",
    "\n",
    "Please use the console to explore it.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# Import seaborn package as sns\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize an 8 by 6 inches plot figure\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# Add a title\n",
    "plt.title('Average Spend by Monthly Cohorts')\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(data=average_quantity, annot=True, cmap='Blues')\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "### Calculate Spend quartiles (q=4)\n",
    "We have created a dataset for you with random CustomerID and Spend values as data. You will now use this dataset to group customers into quartiles based on Spend values and assign labels to each of them.\n",
    "\n",
    "pandas library as been loaded as pd. Feel free to print the data to the console.\n",
    "\n",
    "\n",
    "```python\n",
    "CustomerID  Spend\n",
    "0           0    137\n",
    "1           1    335\n",
    "2           2    172\n",
    "3           3    355\n",
    "4           4    303\n",
    "5           5    233\n",
    "6           6    244\n",
    "7           7    229\n",
    "\n",
    "```\n",
    "```python\n",
    "# Create a spend quartile with 4 groups - a range between 1 and 5\n",
    "spend_quartile = pd.qcut(data['Spend'], q=4, labels=range(1,5))\n",
    "\n",
    "# Assign the quartile values to the Spend_Quartile column in data\n",
    "data['Spend_Quartile'] = spend_quartile\n",
    "\n",
    "# Print data with sorted Spend values\n",
    "print(data.sort_values('Spend'))\n",
    "\n",
    "     CustomerID  Spend Spend_Quartile\n",
    "    0           0    137              1\n",
    "    2           2    172              1\n",
    "    7           7    229              2\n",
    "    5           5    233              2\n",
    "    6           6    244              3\n",
    "    4           4    303              3\n",
    "    1           1    335              4\n",
    "    3           3    355              4\n",
    "\n",
    "```\n",
    "### Calculate Recency deciles (q=10)\n",
    "We have created a dataset for you with random CustomerID and Recency_Days values as data. You will now use this dataset to group customers into quartiles based on Recency_Days values and assign labels to each of them.\n",
    "\n",
    "Be cautious about the labels for this exercise. You will see that the labels are inverse, and will required one additional step in separately creating them. If you need to refresh your memory on the process of creating the labels, check out the slides!\n",
    "\n",
    "The pandas library as been loaded as pd. Feel free to print the data to the console.\n",
    "```python\n",
    "# Store labels from 4 to 1 in a decreasing order\n",
    "r_labels = list(range(4, 0, -1))\n",
    "\n",
    "# Create a spend quartile with 4 groups and pass the previously created labels \n",
    "recency_quartiles = pd.qcut(data['Recency_Days'], q=4, labels=r_labels)\n",
    "\n",
    "# Assign the quartile values to the Recency_Quartile column in `data`\n",
    "data['Recency_Quartile'] = recency_quartiles \n",
    "\n",
    "# Print `data` with sorted Recency_Days values\n",
    "print(data.sort_values('Recency_Days'))\n",
    "\n",
    "    CustomerID  Recency_Days Recency_Quartile\n",
    "    0           0            37                4\n",
    "    3           3            72                4\n",
    "    7           7           133                3\n",
    "    6           6           203                3\n",
    "    1           1           235                2\n",
    "    4           4           255                2\n",
    "    5           5           393                1\n",
    "    2           2           396                1\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "### Calculate RFM values\n",
    "Calculate Recency, Frequency and Monetary values for the online dataset we have used before - it has been loaded for you with recent 12 months of data. There's a TotalSum column in the online dataset which has been calculated by multiplying Quantity and UnitPrice: online['Quantity'] * online['UnitPrice'].\n",
    "\n",
    "Also, we have created a snapshot_date variable that you can use to calculate recency. Feel free to print the online dataset and the snapshot_date into the Console. The pandas library is loaded as pd, and datetime as dt.\n",
    "```python\n",
    "# Calculate Recency, Frequency and Monetary value for each customer \n",
    "datamart = online.groupby(['CustomerID']).agg({\n",
    "    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,\n",
    "    'InvoiceNo': 'count',\n",
    "    'TotalSum': 'sum'})\n",
    "\n",
    "# Rename the columns \n",
    "datamart.rename(columns={'InvoiceDate': 'Recency',\n",
    "                         'InvoiceNo': 'Frequency',\n",
    "                         'TotalSum': 'MonetaryValue'}, inplace=True)\n",
    "\n",
    "# Print top 5 rows\n",
    "print(datamart.head())\n",
    "\n",
    "            Recency  Frequency  MonetaryValue\n",
    "    CustomerID                                   \n",
    "    12747             3         25         948.70\n",
    "    12748             1        888        7046.16\n",
    "    12749             4         37         813.45\n",
    "    12820             4         17         268.02\n",
    "    12822            71          9         146.15\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "```\n",
    "```python\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
